{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691226d2",
   "metadata": {},
   "source": [
    "## **Feature:** Dataset Summaries\n",
    "\n",
    "**Names:** Zim, Dhruv\n",
    "\n",
    "### **What it does**\n",
    "Generates statistical summaries including descriptive statistics (mean, median, mode, variance, std, quartiles), for dataset exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Get API Key\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")\n",
    "    \n",
    "# Import libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Langchain imports\n",
    "from langchain_openai import ChatOpenAI  \n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19299e40",
   "metadata": {},
   "source": [
    "\n",
    "### **Helper Functions**\n",
    "- `calculate_basic_stats(df, columns)`: For specified numeric columns, calculate numeric stats such as: count, missing, mean, median, standard deviation, variance, minimum, maximum, etc.\n",
    "- `calculate_five_number_summary(df, columns)`: For specified numeric columns, calculate 5 number stats (min, max, Q1, median, Q3 , IQR)\n",
    "- `calculate_mode_stats(df, columns)`: Calculate mode, frequency, unique values for specified (all) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60424d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_summary(df, columns=None, metrics=None):\n",
    "    \"\"\"\n",
    "    Returns summary dataframe for given columns of numeric type\n",
    "\n",
    "    - params:\n",
    "        - columns: list[str] or None (defaults to numeric columns)\n",
    "        - metrics: list[str] subset of ['count','missing','mean','std', 'var', 'min','median','q1','q3','max','skew','range', 'iqr']\n",
    "    - returns: pd.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Default to numeric columns if no specific columns given\n",
    "    if columns:\n",
    "        columns = [col for col in columns if col in df.columns and pd.api.types.is_numeric_dtype(df[col])]\n",
    "    else:\n",
    "        columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    if not columns:\n",
    "        return pd.DataFrame\n",
    "\n",
    "    filtered_df = df[columns]\n",
    "\n",
    "    # Default metric set\n",
    "    default_metrics = {\n",
    "        \"count\": filtered_df.count(),\n",
    "        \"missing\": filtered_df.isna().sum(),\n",
    "        \"mean\": filtered_df.mean(),\n",
    "        \"std\": filtered_df.std(),\n",
    "        \"var\": filtered_df.var(),\n",
    "        \"min\": filtered_df.min(),\n",
    "        \"q1\": filtered_df.quantile(0.25),\n",
    "        \"median\": filtered_df.median(),\n",
    "        \"q3\": filtered_df.quantile(0.75),\n",
    "        \"max\": filtered_df.max(),\n",
    "        \"skew\": filtered_df.skew(),\n",
    "        \"iqr\": filtered_df.quantile(0.75) - filtered_df.quantile(0.25), \n",
    "        \"range\": filtered_df.max() - filtered_df.min()\n",
    "    }\n",
    "    \n",
    "    # Filter to requested metrics (always including count)\n",
    "    if metrics:\n",
    "        metrics = {m.lower() for m in metrics}\n",
    "        output_cols = {\"count\": default_metrics[\"count\"]}\n",
    "        for d in default_metrics:\n",
    "            if d != \"count\" and d in metrics:\n",
    "                output_cols[d] = default_metrics[d]\n",
    "    else:\n",
    "        output_cols = default_metrics\n",
    "    \n",
    "    output_df = pd.DataFrame(output_cols)\n",
    "    print(output_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d35af88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_summary(df, columns=None, metrics=None):\n",
    "    \"\"\"\n",
    "    Returns summary dataframe for given columns of categorical type\n",
    "\n",
    "    - params:\n",
    "        - columns: list[str] or None (defaults to non-numeric columns)\n",
    "        - metrics: list[str] subset of ['count', 'missing', 'nunique', 'mode', 'top_freq']\n",
    "    - returns: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Default to non-numeric columns if no specific columns given\n",
    "    if columns:\n",
    "        columns = [col for col in columns if col in df.columns]\n",
    "    else:\n",
    "        columns = [col for col in df.select_dtypes(include='object')]\n",
    "\n",
    "    if not columns:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    filtered_df = df[columns]\n",
    "\n",
    "    default_metrics = {\n",
    "        \"count\": filtered_df.count(),\n",
    "        \"missing\": filtered_df.isna().sum(),\n",
    "        \"nunique\": filtered_df.nunique(dropna=True),\n",
    "        \"mode\": filtered_df.apply(lambda col: col.mode(dropna=True).iloc[0] if not col.mode(dropna=True).empty else np.nan),\n",
    "        \"top_freq\": filtered_df.apply(lambda col: col.value_counts(dropna=True).iloc[0] if not col.value_counts(dropna=True).empty else 0)\n",
    "    }\n",
    "    if metrics:\n",
    "        metrics = {m.lower() for m in metrics}\n",
    "        output_cols = {\"count\": default_metrics[\"count\"]}\n",
    "        for d in default_metrics:\n",
    "            if d != \"count\" and d in metrics:\n",
    "                output_cols[d] = default_metrics[d]\n",
    "    else:\n",
    "        output_cols = default_metrics\n",
    "\n",
    "    output_df = pd.DataFrame(output_cols)\n",
    "    print(output_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dffed275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mode_stats(df, columns=None, metrics=None):\n",
    "    \"\"\"\n",
    "    Returns summary dataframe for given columns of categorical type\n",
    "\n",
    "    - params:\n",
    "        - columns: list[str] or None\n",
    "        - metrics: list[str] subset of ['mode', 'mode_freq', 'unique_vals', 'most_freq']\n",
    "    - returns: pd.DataFrame\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "\n",
    "    # Default metrics\n",
    "    all_metrics = ['mode', 'mode_freq', 'unique_vals', 'most_freq']\n",
    "    if metrics is not None:\n",
    "        metrics = [m for m in metrics if m in all_metrics]\n",
    "    else:\n",
    "        metrics = all_metrics\n",
    "\n",
    "    mode_stats = {}\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            stats = {\n",
    "                'mode': df[col].mode().iloc[0] if not df[col].mode().empty else None,\n",
    "                'mode_freq': df[col].value_counts().iloc[0] if not df[col].value_counts().empty else 0,\n",
    "                'unique_vals': df[col].nunique(),\n",
    "                'most_freq': df[col].value_counts().head(3).to_dict()\n",
    "            }\n",
    "            # Only keep requested metrics\n",
    "            mode_stats[col] = {k: stats[k] for k in metrics}\n",
    "    print(mode_stats)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d10dbc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_docs = \"\"\" Helper functions available: \n",
    "- numerical_summary(df, columns=None, metrics=None): Returns a numeric summary DataFrame for given columns. \n",
    "prints summary of given metrics for given columns in dataframe of numeric type only\n",
    "    - params:\n",
    "        - columns: list[str] or None (defaults to numeric columns)\n",
    "        - metrics: list[str] subset of [\"count\",\"missing\",\"mean\",\"std\",\"min\",\"median\",\"q1\",\"q3\",\"max\",\"skew\",\"range\", \"iqr\"]\n",
    "\n",
    "- def categorical_summary(df, columns=None, metrics=None)\n",
    "prints summary of given metrics for given columns in dataframe\n",
    "    - params:\n",
    "        - columns: list[str] or None (defaults to non-numeric columns)\n",
    "        - metrics: list[str] subset of ['count', 'missing', 'nunique', 'mode', 'top_freq']\n",
    "\n",
    "- def calculate_mode_stats(df, columns=None, metrics=None): \n",
    "prints summary of given metrics for given columns in dataframe\n",
    "    - params:\n",
    "        - columns: list[str] or None (defaults to non-numeric columns)\n",
    "        - metrics: list[str] subset of ['mode', 'mode_freq', 'unique_vals', 'most_freq']\n",
    "\n",
    "Examples:\n",
    "- \"Find cardinality of categorical columns\" -> def categorical_summary(df, columns=None, metrics=['nunique'])\n",
    "- \"summary of all data\" -> use multiple helper functions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887eeff7",
   "metadata": {},
   "source": [
    "# **MAIN FEATURE FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summaries(df, user_query):\n",
    "    \"\"\"\n",
    "    Main function that gets called by the main router.\n",
    "    MUST take (user_query, df) and return df\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create message chain\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(content=helper_docs))\n",
    "    messages.append(SystemMessage(content=f\"\"\"\n",
    "    You are a data cleaning agent trying to generate dataset summaries.\n",
    "    \n",
    "    Dataset info: Shape: {df.shape}, Sample: {df.head(3).to_string()}\n",
    "\n",
    "    Libraries available:\n",
    "    - pd (pandas), np (numpy)\n",
    "    - math, re, datetime\n",
    "    \n",
    "    BASIC SUMMARIES\n",
    "    - df.shape(): rows and columns\n",
    "    - 5 number summary (numerical): 'IQR', 'Q3', 'Q1', 'Median', 'Mean' \n",
    "    - (categorical): mode, nunique, top_freq\n",
    "\n",
    "    Rules:\n",
    "    - Return only executable Python code, no explanations, no markdown blocks\n",
    "    - Use helper functions if needed\n",
    "    - For specific columns mentioned in query, pass them as lists to helper functions\n",
    "    - ASSUME DF IS ALREADY DEFINED\n",
    "    - In order to generate a response/message to the user use print statements\n",
    "    print(\"message\")\n",
    "    - Write a detailed print message to summarise actions taken and reasons\n",
    "    \"\"\"))\n",
    "    messages.append(HumanMessage(content=f\"User request: {user_query}\"))\n",
    "    \n",
    "    # Call LLM with message chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    generated_code = response.content.strip()\n",
    "    \n",
    "    # Execute code\n",
    "    try:\n",
    "        original_df = df.copy()\n",
    "        exec(generated_code)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Generated Code:{generated_code}\")\n",
    "        return original_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bef74e",
   "metadata": {},
   "source": [
    "# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter CSV filename from \"datasets\" folder\n",
    "dataset_name = \"Life Expectancy Data.csv\"\n",
    "\n",
    "# Build CSV path (to avoid import errors)\n",
    "load_dotenv()\n",
    "PROJECT_ROOT = Path(os.environ[\"PROJECT_ROOT\"])\n",
    "path = PROJECT_ROOT / \"datasets\" / dataset_name\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "test_df = df.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-cleaning-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
