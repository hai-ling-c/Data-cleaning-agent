{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691226d2",
   "metadata": {},
   "source": [
    "## **Feature:** Missing Vals\n",
    "\n",
    "**Names:** Tanat\n",
    "\n",
    "### **What it does**\n",
    "Intelligently handles missing values in datasets using data cleaning best practices. The feature analyzes your data's characteristics (data types, distribution, missing percentages) and automatically suggests or applies the most appropriate imputation method.\n",
    "\n",
    "Users can either get imputation recommendations or have the system automatically clean their data based on best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff1f7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Get API Key\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")\n",
    "\n",
    "# Import libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Langchain imports\n",
    "from langchain_openai import ChatOpenAI  \n",
    "from langchain.schema import HumanMessage, SystemMessage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866b0e98",
   "metadata": {},
   "source": [
    "### **Helper Functions**\n",
    "\n",
    "- `analyze_missing_values(df, drop_threshold=0.5)` = Suggest missing vlaue imputation strategies based on best practices/heuristics\n",
    "- `auto_impute(df, drop_threshold=0.5)` = Automatically imputes missing values in a DataFrame based on simple best-practice heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60424d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(df, drop_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Suggest missing value imputation strategies based on heuristics.\n",
    "    \"\"\"\n",
    "    suggestions = {}\n",
    "    for col in df.columns:\n",
    "        print(col)\n",
    "        missing_pct = df[col].isna().mean()\n",
    "        dtype = df[col].dtype\n",
    "        suggestion = None\n",
    "\n",
    "        if missing_pct == 0:\n",
    "            continue\n",
    "        if missing_pct > drop_threshold:\n",
    "            suggestion = \"Drop column (too many missing values)\"\n",
    "        else:\n",
    "            # Numerical features\n",
    "            if pd.api.types.is_numeric_dtype(dtype):\n",
    "                n_unique = df[col].nunique(dropna=True)\n",
    "                if n_unique < 15:  # numeric but categorical (like codes)\n",
    "                    suggestion = \"Mode imputation (numeric categorical)\"\n",
    "                else:\n",
    "                    non_null = df[col].dropna()\n",
    "                    if len(non_null) < 10:\n",
    "                        suggestion = \"Median imputation (small sample)\"\n",
    "                    else:\n",
    "                        skewness = non_null.skew()\n",
    "                        suggestion = \"Mean imputation\" if abs(skewness) < 1 else \"Median imputation (skewed)\"\n",
    "            \n",
    "            # Categorical features\n",
    "            elif pd.api.types.is_categorical_dtype(dtype) or pd.api.types.is_object_dtype(dtype):\n",
    "                n_unique = df[col].nunique(dropna=True)\n",
    "                if n_unique <= 10:\n",
    "                    suggestion = \"Mode imputation (most frequent)\"\n",
    "                else:\n",
    "                    suggestion = \"Impute with 'Unknown' or predictive model\"\n",
    "\n",
    "            # Boolean features\n",
    "            elif pd.api.types.is_bool_dtype(dtype):\n",
    "                suggestion = \"Mode imputation (True/False)\"\n",
    "\n",
    "            # Datetime features\n",
    "            elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "                suggestion = \"Forward/Backward fill or interpolation (time series)\"\n",
    "            \n",
    "            else:\n",
    "                suggestion = \"Custom handling needed\"\n",
    "\n",
    "        suggestions[col] = {\n",
    "            \"dtype\": str(dtype),\n",
    "            \"missing_pct\": round(missing_pct, 3),\n",
    "            \"suggestion\": suggestion\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame.from_dict(suggestions, orient=\"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e6386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_impute(df, drop_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Automatically imputes missing values in a DataFrame based on simple \n",
    "    best-practice heuristics.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        missing_pct = df[col].isna().mean()\n",
    "        dtype = df[col].dtype\n",
    "\n",
    "        # Drop if too many missing\n",
    "        if missing_pct > drop_threshold:\n",
    "            df = df.drop(columns=[col])\n",
    "            continue\n",
    "\n",
    "        # Numerical features (mean or median)\n",
    "        if np.issubdtype(dtype, np.number):\n",
    "            skewness = df[col].dropna().skew()\n",
    "            if abs(skewness) < 1:\n",
    "                fill_value = df[col].mean()\n",
    "                print(f\"Imputed '{col}' with mean\")\n",
    "            else:\n",
    "                fill_value = df[col].median()\n",
    "                print(f\"'{col}' is skewed, imputed with median\")\n",
    "            df[col] = df[col].fillna(fill_value)\n",
    "\n",
    "        # Categorical features\n",
    "        elif df[col].dtype == \"object\" or pd.api.types.is_categorical_dtype(df[col]):\n",
    "            n_unique = df[col].nunique(dropna=True)\n",
    "            unique_ratio = n_unique / df.shape[0]\n",
    "            # Low Cardinality Fill with median else impute with unknown \n",
    "            if n_unique <= 20 or unique_ratio < 0.05:\n",
    "                fill_value = df[col].mode(dropna=True)[0] if not df[col].mode(dropna=True).empty else \"Unknown\"\n",
    "                df[col] = df[col].fillna(fill_value)\n",
    "                print(f\"{col} has low Cardinality, imputed with mode\")\n",
    "            else:\n",
    "                df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "        # Datetime features\n",
    "        elif np.issubdtype(dtype, np.datetime64):\n",
    "            df[col] = df[col].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "        # Fallback\n",
    "        else:\n",
    "            df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e2b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_col(series, strategy):\n",
    "    \"\"\"\n",
    "    Impute missing values in a pandas Series using the specified strategy.\n",
    "    Supported strategies: 'mean', 'median', 'mode', 'unknown', 'ffill', 'bfill'\n",
    "    \"\"\"\n",
    "    if strategy == \"mean\":\n",
    "        fill_value = series.mean()\n",
    "        return series.fillna(fill_value)\n",
    "    elif strategy == \"median\":\n",
    "        fill_value = series.median()\n",
    "        return series.fillna(fill_value)\n",
    "    elif strategy == \"mode\":\n",
    "        fill_value = series.mode(dropna=True)[0] if not series.mode(dropna=True).empty else \"Unknown\"\n",
    "        return series.fillna(fill_value)\n",
    "    elif strategy == \"unknown\":\n",
    "        return series.fillna(\"Unknown\")\n",
    "    elif strategy == \"ffill\":\n",
    "        return series.fillna(method=\"ffill\")\n",
    "    elif strategy == \"bfill\":\n",
    "        return series.fillna(method=\"bfill\")\n",
    "    else:\n",
    "        print(f\"Unknown strategy '{strategy}', no imputation performed.\")\n",
    "        return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b21dd952",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_docs = \"\"\" Helper functions available: \n",
    "- auto_impute(df, drop_threshold=0.5): Automatically imputes missing values in a DataFrame based on simple best-practice heuristics.\n",
    "- impute_col(series, strategy): Impute missing values in a pandas Series using the specified strategy. and returns modified series\n",
    "    - Supported Strategies: 'mean', 'median', 'mode', 'unknown', 'ffill', 'bfill'\n",
    "\n",
    "Examples:\n",
    "- df = auto_impute(df)\n",
    "- df[col] = impute_col(df[col], 'mean')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34049fe8",
   "metadata": {},
   "source": [
    "# **MAIN FEATURE FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54132b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_vals(df, user_query):\n",
    "    \"\"\"\n",
    "    Main function that gets called by the main router.\n",
    "    MUST take (user_query, df) and return df\n",
    "    \"\"\"\n",
    "    \n",
    "    suggestions = analyze_missing_values(df)\n",
    "\n",
    "    # Create message chain\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(content=helper_docs))\n",
    "    messages.append(SystemMessage(content=f\"\"\"\n",
    "    You are a data cleaning agent trying to generate dataset summaries.\n",
    "    \n",
    "    Dataset info: Shape: {df.shape}, Sample: {df.head(3).to_string()}\n",
    "    \n",
    "    imputation suggestions: {suggestions if not suggestions.empty else \"No Missing Values!\"}\n",
    "\n",
    "    Libraries available:\n",
    "    - pd (pandas), np (numpy)\n",
    "    - math, re, datetime\n",
    "    - preprocessing, impute (from sklearn)\n",
    "    \n",
    "    Rules:\n",
    "    - Return only executable Python code, no explanations, no markdown blocks\n",
    "    - Use helper functions if needed\n",
    "    - ASSUME \"df\" IS ALREADY DEFINED\n",
    "    - In order to generate a response/message to the user use print statements\n",
    "    print(\"message\")\n",
    "    - Write a detailed print message to summarise actions taken and reasons\n",
    "    \"\"\"))\n",
    "    messages.append(HumanMessage(content=f\"User request: {user_query}\"))\n",
    "    \n",
    "    # Call LLM with message chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    generated_code = response.content.strip()\n",
    "    \n",
    "    # Execute code\n",
    "    try:\n",
    "        original_df = df.copy()\n",
    "        exec(generated_code)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Generated Code:{generated_code}\")\n",
    "        return original_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b14a9",
   "metadata": {},
   "source": [
    "# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1082194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter CSV filename from \"datasets\" folder\n",
    "dataset_name = \"Life Expectancy Data.csv\"\n",
    "\n",
    "# Build CSV path (to avoid import errors)\n",
    "load_dotenv()\n",
    "PROJECT_ROOT = Path(os.environ[\"PROJECT_ROOT\"])\n",
    "path = PROJECT_ROOT / \"datasets\" / dataset_name\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "test_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c684d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = missing_vals(df, \"Analyse missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425fe256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['Population'].isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-cleaning-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
