{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691226d2",
   "metadata": {},
   "source": [
    "## **Feature:** outliers\n",
    "\n",
    "**Names:** Hailing Chen\n",
    "\n",
    "### **What it does**\n",
    "Automatically detects outliers and recommends optimal handling strategies based on your data's characteristics. Analyzes distribution patterns, sample sizes, and column types to suggest whether to cap, remove, transform, or fill outlier values. \n",
    "\n",
    "Provides context-aware recommendations like \"Transform (highly skewed data)\" or \"Remove outliers (large dataset)\" to help you make informed data cleaning decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff1f7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Get API Key\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")\n",
    "\n",
    "# Import libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import io\n",
    "import contextlib\n",
    "\n",
    "# Langchain imports\n",
    "from langchain_openai import ChatOpenAI  \n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a88657",
   "metadata": {},
   "source": [
    "### **Helper Functions**\n",
    "\n",
    "- `analyze_outliers(df, iqr_multiplier=1.5, z_threshold=3, contamination=0.1)`: Analyze outliers and suggest handling strategies based on heuristics.\n",
    "- `get_outlier_details(df, col, method='iqr', iqr_multiplier=1.5, z_threshold=3)`: Get detailed information about outliers in a specific column\n",
    "- `handle_outliers(df, col, method='cap', percentiles=(5, 95), fill_value=None)`: Handle outliers in a specific column using methods including 'cap', 'remove', 'transform', 'fill'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60424d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_outliers(df, iqr_multiplier=1.5, z_threshold=3, contamination=0.1):\n",
    "    \"\"\"\n",
    "    Analyze outliers and suggest handling strategies based on heuristics.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - iqr_multiplier: multiplier for IQR method (default 1.5)\n",
    "    - z_threshold: threshold for Z-score method (default 3)\n",
    "    - contamination: expected proportion of outliers for isolation forest (default 0.1)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with outlier analysis and suggestions for each numeric column\n",
    "    \"\"\"\n",
    "    \n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "    suggestions = {}\n",
    "    \n",
    "    # Only analyze numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        col_result = {}\n",
    "        if df[col].isna().all():\n",
    "            continue\n",
    "            \n",
    "        clean_data = df[col].dropna()\n",
    "        col_result[\"dtype\"] = str(df[col].dtype)\n",
    "        col_result['sample_size'] = len(clean_data)\n",
    "        # if len(clean_data) < 10:  # Skip if too few data points\n",
    "        #     col_result['suggestion'] = \"Insufficient data for outlier detection\"\n",
    "            # suggestions[col] = {\n",
    "            #     \"dtype\": str(df[col].dtype),\n",
    "            #     \"sample_size\": len(clean_data),\n",
    "            #     \"outliers_iqr\": 0,\n",
    "            #     \"outliers_zscore\": 0,\n",
    "            #     \"outlier_pct\": 0,\n",
    "            #     \"suggestion\": \"Insufficient data for outlier detection\"\n",
    "            # }\n",
    "            # continue\n",
    "        \n",
    "        try:\n",
    "            # IQR Method\n",
    "            Q1 = clean_data.quantile(0.25)\n",
    "            Q3 = clean_data.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            if IQR == 0:  # No variance in data\n",
    "                col_result[\"suggestion\"] = \"No variance in data - all values are the same\"\n",
    "                suggestions[col] = col_result\n",
    "                continue\n",
    "                \n",
    "            lower_bound = Q1 - iqr_multiplier * IQR\n",
    "            upper_bound = Q3 + iqr_multiplier * IQR\n",
    "            outliers_iqr = ((clean_data < lower_bound) | (clean_data > upper_bound)).sum()\n",
    "            col_result[\"outliers_iqr\"] = outliers_iqr\n",
    "        except Exception as e:\n",
    "            col_result[\"outliers_iqr\"] = 'error'\n",
    "        \n",
    "        try:\n",
    "            # Z-Score Method\n",
    "            z_scores = np.abs(stats.zscore(clean_data))\n",
    "            outliers_zscore = (z_scores > z_threshold).sum()\n",
    "            col_result[\"outliers_zscore\"] = outliers_zscore\n",
    "        except Exception as e:\n",
    "            col_result[\"outliers_zscore\"] = 'error'\n",
    "        \n",
    "        # Take the more conservative estimate\n",
    "        outlier_count = min(col_result[\"outliers_iqr\"], col_result[\"outliers_zscore\"])\n",
    "        col_result[\"outlier_pct\"] = round(outlier_count / len(clean_data), 3)\n",
    "        \n",
    "        try:\n",
    "            # Additional statistics for decision making\n",
    "            n_unique = clean_data.nunique()\n",
    "            col_result[\"skewness\"] = round(clean_data.skew(), 3)\n",
    "            col_result[\"kurtosis\"] = round(clean_data.kurtosis(), 3)\n",
    "            data_range = clean_data.max() - clean_data.min()\n",
    "        except Exception as e:\n",
    "            n_unique = len(clean_data.unique()) if len(clean_data) > 0 else 0\n",
    "            col_result[\"skewness\"] = 0.0\n",
    "            col_result[\"kurtosis\"] = 0.0\n",
    "            data_range = 0\n",
    "            print(f\"Statistics calculation error for {col}: {e}\")\n",
    "        \n",
    "                # Generate suggestions based on heuristics\n",
    "        outlier_pct = col_result[\"outlier_pct\"]\n",
    "        skewness = col_result[\"skewness\"]\n",
    "        kurtosis = col_result[\"kurtosis\"]\n",
    "        \n",
    "        try:\n",
    "            # Special cases first (override general rules)\n",
    "            col_lower = str(col).lower()\n",
    "\n",
    "            if len(clean_data) < 10:  # Skip if too few data points\n",
    "                suggestion = \"Insufficient data for outlier detection\"\n",
    "            elif any(keyword in col_lower for keyword in ['id', 'index', 'key']):\n",
    "                suggestion = \"No action needed (ID/Index column)\"\n",
    "            elif 'age' in col_lower and (clean_data < 0).any():\n",
    "                suggestion = \"Cap to realistic range (negative age detected)\"\n",
    "            elif any(keyword in col_lower for keyword in ['price', 'cost', 'amount', 'salary']) and (clean_data < 0).any():\n",
    "                suggestion = \"Remove or cap (negative financial values)\"\n",
    "            elif any(keyword in col_lower for keyword in ['year', 'month', 'day']):\n",
    "                suggestion = \"Investigate outliers (date component)\"\n",
    "            elif any(keyword in col_lower for keyword in ['income', 'salary', 'revenue', 'population', 'sales']) and outlier_pct > 0.01:\n",
    "                suggestion = \"Transform (log transformation for multiplicative data)\"\n",
    "            \n",
    "            # General rules based on outlier percentage\n",
    "            elif outlier_pct == 0:\n",
    "                suggestion = \"No action needed (no outliers detected)\"\n",
    "            \n",
    "            elif outlier_pct > 0.2:  # More than 20% outliers\n",
    "                if n_unique < 20:  # Likely categorical numeric data\n",
    "                    suggestion = \"Investigate data type (possibly categorical codes)\"\n",
    "                else:\n",
    "                    suggestion = \"Investigate data quality (>20% outliers)\"\n",
    "            \n",
    "            elif outlier_pct > 0.1:  # 10-20% outliers\n",
    "                if abs(skewness) > 2:\n",
    "                    suggestion = \"Transform (highly skewed with many outliers)\"\n",
    "                elif col_result[\"sample_size\"] > 1000:  # Large dataset\n",
    "                    suggestion = \"Remove outliers (large dataset can afford data loss)\"\n",
    "                else:\n",
    "                    suggestion = \"Cap outliers (preserve sample size)\"\n",
    "            \n",
    "            elif outlier_pct > 0.05:  # 5-10% outliers\n",
    "                if kurtosis > 3:  # Heavy-tailed distribution\n",
    "                    suggestion = \"Cap at percentiles (heavy-tailed distribution)\"\n",
    "                elif abs(skewness) > 1:\n",
    "                    suggestion = \"Transform or cap (skewed data)\"\n",
    "                elif col_result[\"sample_size\"] < 100:  # Small dataset\n",
    "                    suggestion = \"Fill with median (small dataset)\"\n",
    "                else:\n",
    "                    suggestion = \"Cap at percentiles (moderate outliers)\"\n",
    "            \n",
    "            elif outlier_pct > 0.01:  # 1-5% outliers\n",
    "                if col_result[\"sample_size\"] > 10000:  # Very large dataset\n",
    "                    suggestion = \"Remove outliers (large dataset)\"\n",
    "                elif n_unique < 50 and data_range > 1000:  # Likely measurement errors\n",
    "                    suggestion = \"Fill with median (likely measurement errors)\"\n",
    "                else:\n",
    "                    suggestion = \"Investigate individual cases (low outlier rate)\"\n",
    "            \n",
    "            else:  # Less than 1% outliers\n",
    "                suggestion = \"No action needed (natural variation)\"\n",
    "            \n",
    "            col_result[\"suggestion\"] = suggestion\n",
    "            \n",
    "        except Exception as e:\n",
    "            col_result[\"suggestion\"] = f\"Error generating suggestion: {str(e)}\"\n",
    "            print(f\"Suggestion generation error for {col}: {e}\")\n",
    "        \n",
    "        # Ensure all required keys are present with proper types\n",
    "        suggestions[col] = col_result\n",
    "        \n",
    "    output_df = pd.DataFrame.from_dict(suggestions, orient=\"index\")\n",
    "    output_df.index.name = \"variable\"\n",
    "    markdown_table = output_df.to_markdown()\n",
    "    markdown_table += \"\\n\\n---\\n\"\n",
    "    return print(markdown_table)\n",
    "\n",
    "    # return pd.DataFrame.from_dict(suggestions, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c34ae9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, col, method='cap', percentiles=(5, 95), fill_value=None):\n",
    "    \"\"\"\n",
    "    Handle outliers in a specific column using various methods.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - col: column name to process\n",
    "    - method: 'cap', 'remove', 'transform', 'fill'\n",
    "    - percentiles: tuple for capping (lower, upper percentiles)\n",
    "    - fill_value: value to fill outliers with (for 'fill' method)\n",
    "    \n",
    "    Returns:\n",
    "    - Modified DataFrame\n",
    "    \"\"\"\n",
    "    if col not in df.columns:\n",
    "        print(f\"Column '{col}' not found\")\n",
    "        return df\n",
    "    \n",
    "    if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "        print(f\"Column '{col}' is not numeric\")\n",
    "        return df\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    if method == 'cap':\n",
    "        lower_cap = df_copy[col].quantile(percentiles[0] / 100)\n",
    "        upper_cap = df_copy[col].quantile(percentiles[1] / 100)\n",
    "        df_copy[col] = df_copy[col].clip(lower=lower_cap, upper=upper_cap)\n",
    "        print(f\"Capped outliers in '{col}' to [{lower_cap:.2f}, {upper_cap:.2f}]\")\n",
    "    \n",
    "    elif method == 'remove':\n",
    "        Q1 = df_copy[col].quantile(0.25)\n",
    "        Q3 = df_copy[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        before_count = len(df_copy)\n",
    "        df_copy = df_copy[(df_copy[col] >= lower_bound) & (df_copy[col] <= upper_bound)]\n",
    "        after_count = len(df_copy)\n",
    "        print(f\"Removed {before_count - after_count} outlier rows from '{col}'\")\n",
    "    \n",
    "    elif method == 'transform':\n",
    "        # Log transformation for positive skewed data\n",
    "        if (df_copy[col] > 0).all():\n",
    "            df_copy[col] = np.log1p(df_copy[col])\n",
    "            print(f\"Applied log transformation to '{col}'\")\n",
    "        else:\n",
    "            print(f\"Cannot apply log transformation to '{col}' (contains non-positive values)\")\n",
    "            return df\n",
    "    \n",
    "    elif method == 'fill':\n",
    "        if fill_value is None:\n",
    "            fill_value = df_copy[col].median()\n",
    "        \n",
    "        Q1 = df_copy[col].quantile(0.25)\n",
    "        Q3 = df_copy[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outlier_mask = (df_copy[col] < lower_bound) | (df_copy[col] > upper_bound)\n",
    "        outlier_count = outlier_mask.sum()\n",
    "        df_copy.loc[outlier_mask, col] = fill_value\n",
    "        print(f\"Filled {outlier_count} outliers in '{col}' with {fill_value}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"Unknown strategy '{method}', outliers not handled.\")\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c99ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_docs = \"\"\" Helper functions available:\n",
    "- analyze_outliers(df, iqr_multiplier=1.5, z_threshold=3, contamination=0.1): Analyze outliers and suggest handling strategies based on heuristics.\n",
    "- handle_outliers(df, col, method, percentiles=(5, 95), fill_value=None): Handle outliers in a specific column using methods defined.\n",
    "    - supported methods: 'cap', 'remove', 'transform', 'fill'\n",
    "    - 'cap' limits extreme values to specified percentiles without removing data points.\n",
    "    - 'remove' removes outliers outside of IQR.\n",
    "    - 'transform' applies log transformation to the specific column\n",
    "    - 'fill' replaces outlier values with a specified value (default: median) or a custom value.\n",
    "\n",
    "EXAMPLES:\n",
    "- Print(analyze_outliers(df))\n",
    "- User: apply log transformation to the column named 'a', Generatedf: df['a'] = handle_outliers(df, 'a', method='transform')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09899c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers = {\n",
    "    \"analyze_outliers\": analyze_outliers,\n",
    "    \"handle_outliers\": handle_outliers,\n",
    "    # add more here\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b02315b",
   "metadata": {},
   "source": [
    "# **MAIN FEATURE FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(df, message):\n",
    "    \"\"\"\n",
    "    Main function that gets called by the main router.\n",
    "    MUST take (df, message) and return df\n",
    "    \"\"\"\n",
    "    # suggestions = analyze_outliers(df)\n",
    "    \n",
    "    # Create message chain\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(content=helper_docs))\n",
    "    messages.append(SystemMessage(content=f\"\"\"\n",
    "    You are a data cleaning agent trying to handle outliers.\n",
    "    \n",
    "    Dataset info: Shape: {df.shape}, Sample: {df.head(3).to_string()}\n",
    "\n",
    "    Libraries available:\n",
    "    - pd (pandas), np (numpy)\n",
    "    - math, re, datetime\n",
    "    - states from spicy\n",
    "    \n",
    "    Rules:\n",
    "    - use analyze_outlier to provide information on outliers to user\n",
    "    - Return only executable Python code, no explanations, no markdown blocks\n",
    "    - Use helper functions if needed\n",
    "    - ASSUME \"df\" IS ALREADY DEFINED\n",
    "    - In order to generate a response/message to the user use PRINT STATEMENTS: print(\"message\")\n",
    "    - Write a detailed print message to summarise actions taken and reasons, such as suggestions and potential actions \n",
    "    \"\"\"))\n",
    "    messages.append(HumanMessage(content=f\"User request: {message}\"))\n",
    "    \n",
    "    # Call LLM with message chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    generated_code = response.content.strip()\n",
    "    \n",
    "    buffer = io.StringIO()\n",
    "    try:\n",
    "        exec_globals = {\"df\": df, \n",
    "                        \"pd\": pd, \n",
    "                        \"np\": np,\n",
    "                        \"stats\": stats,\n",
    "                        **helpers}\n",
    "        with contextlib.redirect_stdout(buffer):\n",
    "            exec(generated_code, exec_globals)\n",
    "        output = buffer.getvalue().strip()\n",
    "        \n",
    "        if not output:\n",
    "            output = \"Code executed, but nothing was printed.\"\n",
    "        return output\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error running code:\\n{e}\\n\\nGenerated code:\\n{generated_code}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30928b6",
   "metadata": {},
   "source": [
    "# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b618978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Enter CSV filename from \"datasets\" folder\n",
    "# dataset_name = \"sample-data.csv\"\n",
    "\n",
    "# # Build CSV path (to avoid import errors)\n",
    "# load_dotenv()\n",
    "# PROJECT_ROOT = Path(os.environ[\"PROJECT_ROOT\"])\n",
    "# path = PROJECT_ROOT / \"datasets\" / dataset_name\n",
    "\n",
    "# df = pd.read_csv(path)\n",
    "# test_df = df.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-cleaning-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
