{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain-openai langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c84439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from datetime import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630ff13",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b5457",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_dataframe_info() -> str:\n",
    "    \"\"\"Get basic information about the DataFrame including shape, columns, and data types.\"\"\"\n",
    "    info = {\n",
    "        \"shape\": df.shape,\n",
    "        \"columns\": list(df.columns),\n",
    "        \"dtypes\": {col: str(dtype) for col, dtype in df.dtypes.items()},\n",
    "        \"memory_usage\": f\"{df.memory_usage(deep=True).sum()} bytes\"\n",
    "    }\n",
    "    return json.dumps(info, indent=2)\n",
    "\n",
    "@tool\n",
    "def get_column_stats(column_name: str) -> str:\n",
    "    \"\"\"Get statistical summary for a specific column.\"\"\"\n",
    "    if column_name not in df.columns:\n",
    "        return f\"Column '{column_name}' not found. Available columns: {list(df.columns)}\"\n",
    "    \n",
    "    col = df[column_name]\n",
    "    \n",
    "    if col.dtype in ['int64', 'float64']:\n",
    "        stats = {\n",
    "            \"count\": col.count(),\n",
    "            \"mean\": col.mean(),\n",
    "            \"std\": col.std(),\n",
    "            \"min\": col.min(),\n",
    "            \"25%\": col.quantile(0.25),\n",
    "            \"50%\": col.median(),\n",
    "            \"75%\": col.quantile(0.75),\n",
    "            \"max\": col.max()\n",
    "        }\n",
    "    else:\n",
    "        stats = {\n",
    "            \"count\": col.count(),\n",
    "            \"unique\": col.nunique(),\n",
    "            \"top\": col.mode().iloc[0] if not col.mode().empty else \"N/A\",\n",
    "            \"freq\": col.value_counts().iloc[0] if len(col.value_counts()) > 0 else 0\n",
    "        }\n",
    "    \n",
    "    return json.dumps(stats, indent=2)\n",
    "\n",
    "@tool\n",
    "def get_missing_values() -> str:\n",
    "    \"\"\"Check for missing values in the DataFrame.\"\"\"\n",
    "    missing = df.isnull().sum()\n",
    "    missing_dict = {col: int(count) for col, count in missing.items()}\n",
    "    total_missing = missing.sum()\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"total_missing_values\": int(total_missing),\n",
    "        \"missing_by_column\": missing_dict,\n",
    "        \"percentage_missing\": {col: round((count/len(df))*100, 2) for col, count in missing_dict.items()}\n",
    "    }, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f69ab",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame for testing\n",
    "sample_data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'age': [25, 30, 35, 28, 22],\n",
    "    'salary': [50000, 75000, 90000, 60000, 45000],\n",
    "    'department': ['Engineering', 'Sales', 'Engineering', 'Marketing', 'Sales'],\n",
    "    'years_experience': [3, 8, 12, 5, 1]\n",
    "}\n",
    "df = pd.read_csv(\"../datasets/smoke.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e42351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GPT-4o-mini with tool calling enabled\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "# Check if the model supports tool calling\n",
    "print(f\"Model: {llm.model_name}\")\n",
    "print(f\"Supports tool calling: {hasattr(llm, 'bind_tools')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all tools imported from pandas_tools.ipynb (doesn't work)\n",
    "# tools = pandas_tools.tools\n",
    "\n",
    "# Local tools\n",
    "tools = [get_dataframe_info, get_column_stats, get_missing_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a736a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"Available pandas tools:\")\n",
    "for tool_func in tools:\n",
    "    print(f\"- {tool_func.name}: {tool_func.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7e5a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful data analysis assistant. You have access to pandas DataFrame tools that can help analyze data.\n",
    "    \n",
    "    The current DataFrame contains employee information with columns: name, age, salary, department, years_experience.\n",
    "\n",
    "    When users ask about data analysis, use the appropriate tools to get the information they need.\n",
    "    Always provide clear, helpful explanations of the results.\"\"\"),\n",
    "    (\"placeholder\", \"{chat_history}\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9cba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent using create_tool_calling_agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# Create the agent executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, \n",
    "    tools=tools, \n",
    "    verbose=True,  # Shows which tools are being called\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "print(\"Agent and AgentExecutor created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"input\": \"What's the shape and structure of the DataFrame?\"})\n",
    "print(response['output'])\n",
    "\n",
    "response = agent_executor.invoke({\"input\": \"Are there any missing values in the dataset?\"})\n",
    "print(response['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-cleaning-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
